{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<hr/>\n",
    "\n",
    "# Introduction to Data Science\n",
    "**Tamás Budavári** - budavari@jhu.edu <br/>\n",
    "\n",
    "- Clustering problems\n",
    "- $k$-means clustering\n",
    "- Voronoi tesselation\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font color=\"darkblue\">Clustering</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Learning\n",
    "\n",
    "- The methods in general fall in these 4 categories\n",
    "\n",
    ">|                | Supervised     |         Unsupervised     |\n",
    " |----------------|:--------------:|:------------------------:|\n",
    " | **Discrete**   | Classification | Clustering               |   \n",
    " | **Continuous** | Regression     | Dimensionality Reduction |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering is ...\n",
    "<img src=\"files/clusters.png\" align=right width=200>\n",
    "\n",
    "... the process of collecting a set of objects into groups or clusters of similar items\n",
    "\n",
    "#### For example,\n",
    "\n",
    "- Discover different species of birds based on their photographs\n",
    "- Segment an image based on the pixel colors\n",
    "- Organize news articles that cover the same story\n",
    "\n",
    "<!--<img src=\"http://www.codeproject.com/KB/recipes/439890/clustering-process.png\" width=450 align=left /> -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:,:2] \n",
    "# only the first 2 features\n",
    "\n",
    "scatter(X[:,0],X[:,1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of Algorithms\n",
    "\n",
    "- Flat\n",
    "\n",
    ">1. Start with a random partitioning\n",
    ">2. Iterate to improve the grouping\n",
    "\n",
    "- Hierarchical\n",
    "\n",
    ">1. Greedy grouping of closest: bottom up\n",
    ">2. Greedy splitting of farthest: top down"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat example\n",
    "\n",
    "<img src=files/kmeans.gif>\n",
    "<!--\n",
    "<img src=http://simplystatistics.org/wp-content/uploads/2014/02/kmeans.gif  align=left width=300> -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hierarchical example\n",
    "\n",
    "> Set\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Clusters.svg/250px-Clusters.svg.png width=150 align=center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Dendogram\n",
    "\n",
    "<img src=https://upload.wikimedia.org/wikipedia/commons/thumb/a/ad/Hierarchical_clustering_simple_diagram.svg/418px-Hierarchical_clustering_simple_diagram.svg.png width=250>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-means clustering\n",
    "\n",
    "A simple (flat) algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization\n",
    "\n",
    "- Formally, it's an optimization over the possible groupings of objects\n",
    "\n",
    "> For a set of $\\{ x_l \\}$ where $x_l\\in \\mathbb{R}^d$ for all $l$\n",
    "><br>\n",
    "><br>\n",
    ">$\\displaystyle  \\hat{{C}} = \\textrm{arg}\\min_{{C}} \\sum_{i=1}^k \\left[\\ \\sum_{x\\in{}C_i}\\ \\lvert\\!\\lvert x-\\mu_i\\rvert\\!\\rvert^2 \\right] $\n",
    "><br>\n",
    "><br>\n",
    "> where \n",
    "><br>\n",
    "><br>\n",
    ">$\\displaystyle  \\mu_i = \\frac{1}{\\lvert{C_i}\\rvert}\\sum_{x\\in{}C_i} x $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm\n",
    "\n",
    "- Iteratively improving the $\\mu_i$ **prototypes** of $k$ clusters\n",
    "\n",
    ">1. Pick $k$ random objects as the initial $\\mu_i$ prototypes\n",
    ">0. Find for each object the closest prototype and assign to that cluster\n",
    ">0. Calculate the averages for each cluster to get new $\\mu_i$\n",
    ">0. Repeat until convergence\n",
    "\n",
    "- Often very fast - but no proof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Animation\n",
    "\n",
    "<!--<img src=http://simplystatistics.org/wp-content/uploads/2014/02/kmeans.gif align=left width=300>-->\n",
    "<img src=files/kmeans.gif align=left width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Click on these <a href=http://shabal.in/visuals/kmeans/1.html>animations</a> to see the process of $k$-means clustering in action\n",
    " \n",
    "> Starting from different points..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(6,6)); ax=subplot(aspect='equal')\n",
    "scatter(X[:,0],X[:,1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(init='random', n_clusters=3, n_init=100)\n",
    "kmeans.fit(X)\n",
    "\n",
    "figure(figsize=(6,6)); ax=subplot(aspect='equal')\n",
    "scatter(X[:,0],X[:,1],c=kmeans.labels_,cmap=cm.rainbow);\n",
    "\n",
    "C = kmeans.cluster_centers_\n",
    "scatter(C[:,0],C[:,1],c='k',marker='o',s=300,alpha=0.5,edgecolor='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step size of the mesh. \n",
    "h = .005    # point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "x_min, x_max = X[:, 0].min() -.5, X[:, 0].max() +.5\n",
    "y_min, y_max = X[:, 1].min() -.5, X[:, 1].max() +.5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "# Obtain labels for each point in mesh. Use last trained model.\n",
    "P = kmeans.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot\n",
    "P = P.reshape(xx.shape)\n",
    "figure(figsize=(6,6)); subplot(111,aspect='equal')\n",
    "plt.clf()\n",
    "\n",
    "plt.imshow(P, interpolation='nearest',\n",
    "           extent=(xx.min(), xx.max(), yy.min(), yy.max()),\n",
    "           cmap=plt.cm.Paired,\n",
    "           aspect='equal', origin='lower', alpha=0.7)\n",
    "\n",
    "plt.scatter(X[:, 0], X[:, 1], c='k', alpha=0.7)\n",
    "\n",
    "# Plot the centroids as a white X\n",
    "centroids = kmeans.cluster_centers_\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],\n",
    "            marker='x', s=169, linewidths=3,\n",
    "            color='w', zorder=10, alpha=0.8)\n",
    "\n",
    "plt.xlim(x_min, x_max);\n",
    "plt.ylim(y_min, y_max);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detour: Voronoi Tessellation & Delaunay Triangulation\n",
    "\n",
    "<img src=http://christophermanning.org/images/2012/12/59dfbaa41a678cd39a4cc5b94ab8919740e51d9c.png align=left width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitations\n",
    "\n",
    "- Initialization matters\n",
    "\n",
    "> Rerun multiple times: **n_init** (default=10) <br/>\n",
    "> Smart(er) starting points\n",
    "\n",
    "- Assumes spherical clusters (use of distance function)\n",
    "\n",
    "> Preprocessing becomes important even in simple cases <br>\n",
    "> For example, whitening..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformations might help\n",
    "Z = X.copy()\n",
    "Z[:,0] *= 0.5\n",
    "\n",
    "kmeans = KMeans(n_clusters=2,n_init=100,init='k-means++')\n",
    "kmeans.fit(Z)\n",
    "C, L = kmeans.cluster_centers_, kmeans.labels_\n",
    "\n",
    "figure(figsize=(6,6)); ax=subplot(aspect='equal')\n",
    "scatter(Z[:,0],Z[:,1],c= L, marker='o',s= 30,alpha=0.7,cmap=cm.rainbow);\n",
    "scatter(C[:,0],C[:,1],c='k',marker='o',s=300,alpha=0.5,edgecolor='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What $k$?\n",
    "\n",
    "- How many clusters?\n",
    "\n",
    "> Too many? <br/>\n",
    "> Too few?\n",
    "\n",
    "- Various diagnostics\n",
    "\n",
    "> Check the minimum value of the cost function? <br/>\n",
    "> Characterize the clusters - Gaussian? spherical?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "- Run $k$-means on this [CSV](files/Class-Clusters.csv) file\n",
    "- Try different parameters\n",
    "- How many clusters did you find?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = loadtxt('files/Class-Clusters.csv', delimiter=',')\n",
    "scatter(X[:,0],X[:,1],s=50,alpha=0.3,edgecolor='none');\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $k$-medians clustering\n",
    "\n",
    "Replace mean with median for cluster centers <br>\n",
    "Also, Euclidean ($L_2$) vs Taxicab ($L_1$) distance "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
